{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ambiguousReads.ipynb\n",
    "## Marcus Viscardi,    July 03, 2023\n",
    "***\n",
    "The mains goals of this file are to test out how I want to handle ambiguous reads. There are two main ways I can go about this:\n",
    "\n",
    "1. We could just remove other isoforms for the dataset, thus \"collapsing\" the transcriptome into NMD-sensitive and NMD-insensitive isoforms\n",
    "2. We could try and identify the unique regions of the NMD-sensitive isoforms, so if there is any coverage on those nucleotides, it would be considered NMD-sensitive. This should be more accurate, but require some more serious coding.\n",
    "\n",
    "Overall this is going to require a bit of work. I think I am first going to try to implement the first (#1) solution. As that should be a little quicker. Then we can assess if that is good enough, or if we need to go further (with solution #2).\n",
    "\n",
    "***\n",
    "A lot of this is going to be leaning on code from 'coverageAndTails_wFlairAssignments.ipynb' and modifying it with the above goals in mind!\n",
    "***\n",
    "One of the main takeaways from my old dataloading method was I had to squeeze the FLAIR results a bit to make it work for me. My option here could honestly be to manually assign reads to either the isoform of interest or not..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Old imports from coverageAndTails_wFlairAssignments.ipynb:\n",
    "import pysam\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.insert(0, '/data16/marcus/scripts/nanoporePipelineScripts')\n",
    "import nanoporePipelineCommon as npCommon\n",
    "from nanoporeReadPlotting.finalizingReadAndCoveragePlotting_matplotlib import plot_reads, coverage_plotting_5tera\n",
    "CONVERSION_DICT = {\"xrn-1-5tera\": \"oldN2\",\n",
    "                   \"xrn-1-5tera-smg-6\": \"oldS6\",\n",
    "                   \"5tera_xrn-1-KD_wt\": \"newN2\",\n",
    "                   \"5tera_xrn-1-KD_wt_rerun\": \"newerN2\",\n",
    "                   \"5tera_xrn-1-KD_smg-6_rerun\": \"newerS6\",\n",
    "                   \"5tera_xrn-1-KD_smg-5_rerun\": \"newerS5\",\n",
    "                   \"5tera_xrn-1-KD_smg-5\": \"newS5\",\n",
    "                   \"5tera_xrn-1-KD_smg-6\": \"newS6\",\n",
    "                   \"5tera_xrn-1-KD_smg-7\": \"newS7\",\n",
    "                   \"sPM57\": \"sPM57\",\n",
    "                   \"sPM58\": \"sPM58\",\n",
    "                   }\n",
    "REV_CONVERSION_DICT = {val: key for key, val in CONVERSION_DICT.items()}\n",
    "LIB_NAMES = list(REV_CONVERSION_DICT.keys())\n",
    "\n",
    "output_dir = \"/data16/marcus/working/230703_NMD_readCategorization\" # or /tmp\n",
    "\n",
    "print(f\"Finished imports at: {npCommon.get_dt(for_print=True)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ideas:\n",
    "\n",
    "Let's try to logic through what would be required to do the isoform assignment solly based on the knowledge of which piece of the genome is unique to the NMD-sensitive species. Some initial musings:\n",
    "\n",
    "Would could use a region of coverage to call a read as sensitive or not. The idea would be to calculate coverage for all reads that were assigned to the gene based on FeatureCounts. Then look at the coverage of each read and see if it overlaps with the NMD-sensitive region we identified. If it does, then it is NMD-sensitive, if not, then it is NMD-insensitive.\n",
    "\n",
    "I *could* do this manually, but I think pysam actual has a tool to do this. I think it is called `pysam.fetch()`. I think I can use this to get reads that hit the NMD-sensitive region, then I can use that plus the end of the read to decide if it is NMD-sensitive or not.\n",
    "\n",
    "Limitations (and initial thoughts on how to address them):\n",
    "1. For reads that are genuinely ambiguous because they are not long enough to have coverage, we can look at the mapped \"end\" of the read, if that spanned past the NMD-sensitive region, then we can call it. If it didn't, then it is a **TRUE ambiguous read**!\n",
    "2. If a gene has an NMD isoform that is a skipped region rather than an included region, IDK if we can do the same process. This would be pretty annoying. We could potentially just have it work the opposite way, the function would take a inclusive_or_exclusive tag. So that if something hits the \"identifying\" region of the transcript it would be either NMD-sensitive or not, depending on our input. This would be a bit annoying, but I think it would work.\n",
    "3. IDK how well I could double filter with pysam. B/c I would want to select reads identified by FeatureCounts, THEN identified reads with or without coverage at the \"identifying\" region.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First let's try to see how we can use pysam to get reads that hit a region of the genome. I think we can use `pysam.fetch()` to do this. Let's try it out:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gtf_df = pd.read_parquet('/data16/marcus/genomes/plus_cerENO2_elegansRelease100/230327_allChrs_plus-cerENO2.gtf.parquet')\n",
    "from ambiguousReads import NMD_ISO_REGIONS\n",
    "targets_df = pd.DataFrame.from_dict(NMD_ISO_REGIONS,\n",
    "                                    orient='index').reset_index().rename(columns={'index': 'gene_name',\n",
    "                                                                                  'start': 'nmd_region_start',\n",
    "                                                                                  'end': 'nmd_region_end',\n",
    "                                                                                  'region_is_target': 'nmd_region_is_target'})\n",
    "\n",
    "targets_df = targets_df.merge(gtf_df[gtf_df['gene_name'].isin(targets_df.gene_name) & (gtf_df['feature'] == 'gene')][['gene_name', 'gene_id', 'chr', 'start', 'end', 'strand']])\n",
    "targets_df = targets_df[['gene_name', 'gene_id', 'chr', 'start', 'end', 'strand', 'nmd_region_start', 'nmd_region_end', 'nmd_region_is_target']]\n",
    "targets_df.to_csv(f\"{output_dir}/identifiable_targets_df.csv\", index=False)\n",
    "print(f\"Saving to: {output_dir}/identifiable_targets_df.csv\")\n",
    "targets_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Categorize based on coverage of an \"NMD-region\" (i.e. a region that defines the NMD-sensitive isoform)\n",
    "\n",
    "This works ***amazingly well***\n",
    "\n",
    "Look for the output bam (and index) in the /tmp directory, load that into IGV, and color by tag: nC\n",
    "\n",
    "You can see that the reads are properly filtered for all the genes in the above list!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "target_gene = 'ubl-1'\n",
    "\n",
    "chr, start, end, strand, nmd_start, nmd_end = targets_df.loc[targets_df['gene_name'] == target_gene, ['chr', 'start', 'end', 'strand', 'nmd_region_start', 'nmd_region_end']].values[0]\n",
    "gene_is_reverse = (strand == '-')\n",
    "last_edge = nmd_start if gene_is_reverse else nmd_end\n",
    "comparison_for_edge = f\"<= {nmd_start}\" if gene_is_reverse else f\">= {nmd_end}\"\n",
    "\n",
    "bam_file = Path(npCommon.pick_lib_return_path(REV_CONVERSION_DICT['newerS5'], output_dir_folder='cat_files', file_midfix='cat.sorted.mappedAndPrimary', file_suffix='.bam'))\n",
    "\n",
    "bam = pysam.AlignmentFile(bam_file, 'rb')\n",
    "# Let's make temporary bam files for each of the below groups:\n",
    "# 1. Reads that hit the NMD-sensitive region\n",
    "# 2. Reads that did not hit the NMD-sensitive region\n",
    "# 3. Reads that were ambiguous\n",
    "general_name = f'{output_dir}/{bam_file.parent.parent.parent.stem}.{target_gene}'\n",
    "print(general_name)\n",
    "nmd_bam_path = Path(f'{general_name}.nmd.bam')\n",
    "nmd_bam = pysam.AlignmentFile(nmd_bam_path, 'wb', template=bam)\n",
    "non_nmd_bam_path = Path(f'{general_name}.non_nmd.bam')\n",
    "non_nmd_bam = pysam.AlignmentFile(non_nmd_bam_path, 'wb', template=bam)\n",
    "ambiguous_bam_path = Path(f'{general_name}.ambiguous.bam')\n",
    "ambiguous_bam = pysam.AlignmentFile(ambiguous_bam_path, 'wb', template=bam)\n",
    "\n",
    "\n",
    "nmd_count = 0\n",
    "non_nmd_count = 0\n",
    "ambiguous_count = 0\n",
    "for i, read in enumerate(bam.fetch(chr, start, end)):\n",
    "    if read.is_reverse != gene_is_reverse:\n",
    "        continue\n",
    "    # if eval(f\"read.reference_start {comparison_for_edge}\"):\n",
    "    #     ambiguous_count += 1\n",
    "    #     read.set_tag('nC', 'ambiguous', value_type='Z')\n",
    "    #     ambiguous_bam.write(read)\n",
    "    if gene_is_reverse and eval(f\"read.reference_end <= {nmd_start}\"):\n",
    "        ambiguous_count += 1\n",
    "        read.set_tag('nC', 'ambiguous', value_type='Z')\n",
    "        ambiguous_bam.write(read)\n",
    "    elif not gene_is_reverse and eval(f\"read.reference_start >= {nmd_end}\"):\n",
    "        ambiguous_count += 1\n",
    "        read.set_tag('nC', 'ambiguous', value_type='Z')\n",
    "        ambiguous_bam.write(read)\n",
    "    elif read.get_overlap(nmd_start, nmd_end) >= 5:\n",
    "        nmd_count += 1\n",
    "        read.set_tag('nC', 'nmd_target', value_type='Z')\n",
    "        nmd_bam.write(read)\n",
    "    else:\n",
    "        non_nmd_count += 1\n",
    "        read.set_tag('nC', 'non_nmd_target', value_type='Z')\n",
    "        non_nmd_bam.write(read)\n",
    "\n",
    "print(f\"\\nGene: {target_gene}\\nnmd_count: {nmd_count:>13,}\\nnon_nmd_count: {non_nmd_count:>9,}\\nambig_count: {ambiguous_count:>11,}\\ntotal_count: {nmd_count + ambiguous_count +non_nmd_count:>11,}\")\n",
    "\n",
    "for bam in [nmd_bam, non_nmd_bam, ambiguous_bam]:\n",
    "    bam.close()\n",
    "    pysam.index(bam.filename)  # These samtools methods aren't in the pysam __init__ file, but they work!\n",
    "\n",
    "pysam.merge('-f', f'{general_name}.merge.bam', '--write-index', str(nmd_bam_path), str(non_nmd_bam_path), str(ambiguous_bam_path))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bam_file = Path(npCommon.pick_lib_return_path(REV_CONVERSION_DICT['newerN2'], output_dir_folder='cat_files', file_midfix='cat.sorted.mappedAndPrimary', file_suffix='.bam'))\n",
    "\n",
    "bam = pysam.AlignmentFile(bam_file, 'rb')\n",
    "# Let's make temporary bam files for each of the below groups:\n",
    "# 1. Reads that hit the NMD-sensitive region\n",
    "# 2. Reads that did not hit the NMD-sensitive region\n",
    "# 3. Reads that were ambiguous\n",
    "general_name = f'{output_dir}/{bam_file.parent.parent.parent.stem}.all'\n",
    "nmd_bam_path = Path(f'{general_name}.nmd.bam')\n",
    "nmd_bam = pysam.AlignmentFile(nmd_bam_path, 'wb', template=bam)\n",
    "non_nmd_bam_path = Path(f'{general_name}.non_nmd.bam')\n",
    "non_nmd_bam = pysam.AlignmentFile(non_nmd_bam_path, 'wb', template=bam)\n",
    "ambiguous_bam_path = Path(f'{general_name}.ambiguous.bam')\n",
    "ambiguous_bam = pysam.AlignmentFile(ambiguous_bam_path, 'wb', template=bam)\n",
    "\n",
    "\n",
    "\n",
    "for gene_name in targets_df['gene_name'].unique():\n",
    "    chr, start, end, strand, nmd_start, nmd_end = targets_df.loc[targets_df['gene_name'] == gene_name,\n",
    "    ['chr', 'start', 'end', 'strand', 'nmd_region_start', 'nmd_region_end']].values[0]\n",
    "    \n",
    "    gene_is_reverse = (strand == '-')\n",
    "    gene_is_forward = not gene_is_reverse\n",
    "    last_edge = nmd_start if gene_is_reverse else nmd_end\n",
    "    comparison_for_edge = f\"<= {nmd_start}\" if gene_is_reverse else f\">= {nmd_end}\"\n",
    "    \n",
    "    nmd_count = 0\n",
    "    non_nmd_count = 0\n",
    "    ambiguous_count = 0\n",
    "    \n",
    "    for i, read in enumerate(bam.fetch(chr, start, end)):\n",
    "        if read.is_reverse != gene_is_reverse:\n",
    "            continue\n",
    "        # if eval(f\"read.reference_start {comparison_for_edge}\"):\n",
    "        #     ambiguous_count += 1\n",
    "        #     read.set_tag('nC', 'ambiguous', value_type='Z')\n",
    "        #     ambiguous_bam.write(read)\n",
    "        if gene_is_reverse and eval(f\"read.reference_end <= {nmd_start}\"):\n",
    "            ambiguous_count += 1\n",
    "            read.set_tag('nC', 'ambiguous', value_type='Z')\n",
    "            ambiguous_bam.write(read)\n",
    "        elif not gene_is_reverse and eval(f\"read.reference_start >= {nmd_end}\"):\n",
    "            ambiguous_count += 1\n",
    "            read.set_tag('nC', 'ambiguous', value_type='Z')\n",
    "            ambiguous_bam.write(read)\n",
    "        elif read.get_overlap(nmd_start, nmd_end) >= 5:\n",
    "            nmd_count += 1\n",
    "            read.set_tag('nC', 'nmd_target', value_type='Z')\n",
    "            nmd_bam.write(read)\n",
    "        else:\n",
    "            non_nmd_count += 1\n",
    "            read.set_tag('nC', 'non_nmd_target', value_type='Z')\n",
    "            non_nmd_bam.write(read)\n",
    "    \n",
    "    print(f\"Gene: {gene_name}\\n\\tnmd_count: {nmd_count:>13,}\\n\\tnon_nmd_count: {non_nmd_count:>9,}\\n\\tambig_count: {ambiguous_count:>11,}\\n\\ttotal_count: {nmd_count + ambiguous_count +non_nmd_count:>11,}\")\n",
    "\n",
    "for bam in [nmd_bam, non_nmd_bam, ambiguous_bam]:\n",
    "    bam.close()\n",
    "    pysam.sort(bam.filename, '-o', bam.filename)\n",
    "    pysam.index(bam.filename)  # These samtools methods aren't in the pysam __init__ file, but they work!\n",
    "\n",
    "pysam.merge('-f', f'{general_name}.merge.bam', str(nmd_bam_path), str(non_nmd_bam_path), str(ambiguous_bam_path))\n",
    "pysam.sort(f'{general_name}.merge.bam', '-o', f'{general_name}.merge.bam')\n",
    "pysam.index(f'{general_name}.merge.bam')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "read.__dir__()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
