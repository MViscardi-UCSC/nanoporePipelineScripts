{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# coverageAndTails_wFlairAssignments.ipynb\n",
    "## Marcus Viscardi,    March 07, 2023\n",
    "\n",
    "### Pulling it ALL together\n",
    "So the goal here is going to be to produce a singular plot \n",
    "that contains the three coverage sets (NMD targ, not targ, \n",
    "and ambiguous) AND a paired tail CDF. This will probably \n",
    "require a few things:\n",
    "1. The data wrangling from the tail plot and isoform plot loops in [isoformsFromFLAIR.ipynb](file:///data16/marcus/scripts/nanoporePipelineScripts/fourLibrary5TERA/isoformsFromFLAIR.ipynb)\n",
    "2. Holding onto reads that failed that FLAIR assignment, then calling those ambiguous(?)\n",
    "3. Some crazy matplotlib gridspec layout setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sea\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from itertools import product\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.insert(0, '/data16/marcus/scripts/nanoporePipelineScripts')\n",
    "import nanoporePipelineCommon as npCommon\n",
    "from nanoporeReadPlotting.finalizingReadAndCoveragePlotting_matplotlib import plot_reads, coverage_plotting_5tera\n",
    "\n",
    "# At the isoform edge position we can differentiate cleavage species' parent isoform, left of which, we have enough info to differentiate between the NMD sensitive or insensitive isoforms!\n",
    "# I manually identified that same isoform edge information for the following genes:\n",
    "TARGETS_AND_ISOEDGE_DICT = {\"rpl-30\": [10_436_409, 'left', ['Y106G6H.3c.1']],\n",
    "                            \"rpl-26\": [8_603_272, 'left', ['F28C6.7b.1']],\n",
    "                            \"rpl-3\": [3_868_327, 'left', ['F13B10.2b']],\n",
    "                            \"rpl-1\": [2_876_019, 'right', ['Y71F9AL.13b.4', 'Y71F9AL.13b.2']],\n",
    "                            \"rpl-12\": [13_240_023, 'right', ['JC8.3c.2', 'JC8.3b']],\n",
    "                            \"ubl-1\": [3_068_573, 'left', ['H06I04.4b.1']],\n",
    "                            \"rps-22\": [1_950_996, 'left', ['F53A3.3b.1']],\n",
    "                            # New as of 3/21/23:\n",
    "                            \"odc-1\": [6_898_538, 'right', ['K11C4.4.1']],  # This analysis isn't quite the same... b/c only 1 isoform\n",
    "                            # \"rsp-1\": [0, '', ['W02B12.3b.2']],  # Unsure on this one, TODO: look into this!\n",
    "                            \"hel-1\": [8_327_695, 'right', ['C26D10.2b']],\n",
    "                            \"K08D12.3\": [1_710_405, 'left', ['K08D12.3b.1']],  # mis-annotation here, but nice example\n",
    "                            \"aly-3\": [12_124_246, 'left', ['M18.7b']],\n",
    "                            # As of 6/27/23, I want to plot some Non-NMD targets, but because of how this is designed, I think I need to add them to this list, and just ignore the isoform edge stuff. Let's see if I can figure that out:\n",
    "                            # \"ets-4\": [6_523_000, 'left', ['F22A3.1a.3', 'F22A3.1b.1', 'F22A3.1a.1', 'F22A3.1a.2']],\n",
    "                            # \"xbp-1\": [4_196_000, 'left', ['R74.3a.1', 'R74.3b.1', 'R74.3c.1']],\n",
    "                            # \"zip-1\": [],\n",
    "                            }\n",
    "CONVERSION_DICT = {\"xrn-1-5tera\": \"oldN2\",\n",
    "                   \"xrn-1-5tera-smg-6\": \"oldS6\",\n",
    "                   \"5tera_xrn-1-KD_wt\": \"newN2\",\n",
    "                   \"5tera_xrn-1-KD_wt_rerun\": \"newerN2\",\n",
    "                   \"5tera_xrn-1-KD_smg-6_rerun\": \"newerS6\",\n",
    "                   \"5tera_xrn-1-KD_smg-5_rerun\": \"newerS5\",\n",
    "                   \"5tera_xrn-1-KD_smg-5\": \"newS5\",\n",
    "                   \"5tera_xrn-1-KD_smg-6\": \"newS6\",\n",
    "                   \"5tera_xrn-1-KD_smg-7\": \"newS7\",\n",
    "                   \"sPM57\": \"sPM57\",\n",
    "                   \"sPM58\": \"sPM58\",\n",
    "                   }\n",
    "REV_CONVERSION_DICT = {val: key for key, val in CONVERSION_DICT.items()}\n",
    "LIB_NAMES = list(REV_CONVERSION_DICT.keys())\n",
    "print(f\"Finished imports at: {npCommon.get_dt(for_print=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading up flair and featureCounts gene assignments\n",
    "\n",
    "Plan is to:\n",
    "1. Load the mergedOnReads files for libraries (just oldN2 to start)\n",
    "2. Load flair outputs from the *isoform.read.map.txt file - this will need some parsing (see this [link](https://stackoverflow.com/a/63983021/13316742))\n",
    "3. Load preparsed gtf to add extra bits of info to flair outputs\n",
    "4. Merge flair & gtf, then that with mergedOnReads. Be very specific to do a left merge - b/c I need all the stuff from the mergedOnReads for sure (tails, cigars, etc.)\n",
    "\n",
    "\n",
    "After a first pass there are some edge cases that don't seem great.\n",
    "* A fairly low portion of reads have mismatched assignments between FLAIR and ReadAssign\n",
    "* MOST of these are actually just failures of one system or the other! I can probably just use the successful one for and overwrite the other. Or make a new column rather than overwrite.\n",
    "* There are some reads where both are assigned, but they differ! Annoying, right now I am not sure what to do with these...\n",
    "\n",
    "For now, lets write something to get the best assignment between the two.\n",
    "1. If they match, just grab one.\n",
    "2. If they don't match: See if one failed, then just grab the other one.\n",
    "3. If they don't match and both succeeded: ***(FOR NOW)*** don't trust FLAIR, b/c the actual alignment I am plotting is from the genomic alignment!\n",
    "\n",
    "Here we can see what's happening! Most of the reads actually only have one assignment. There are some reads that don't match, but that's the smallest population. There are also some reads that didn't get assigned by either!\n",
    "![image](./output_files/assignment_plots/230308_assignmentsUpsetPlots_newN2.png)\n",
    "You can also see a very small edge case, where FLAIR makes an assignment, but that gene isn't on the same chromosome as what the read mapped to! These are likely homology issues? It's such a small case here that I think we should just drop those reads. *(We can revisit later if interested...)*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_flair_and_reads(lib_key: str, print_stats=True, path_to_dir_for_assignment_plot=None) -> pd.DataFrame:\n",
    "    def _pick_correct_gene_assignment(row):\n",
    "        flair_assignment = row['gene_name_fromFlair']\n",
    "        flair_biotype = row['gene_biotype_fromFlair']\n",
    "        flair_id = row['gene_id_fromFlair']\n",
    "        flair_chr = row['chr_id_fromFlair']\n",
    "        flair_txn_id = row['transcript_id']\n",
    "        \n",
    "        gene_assignment = row['gene_name_fromReads']\n",
    "        gene_biotype = row['gene_biotype_fromReads']\n",
    "        gene_id = row['gene_id_fromReads']\n",
    "        gene_chr = row['chr_id']\n",
    "        \n",
    "        if flair_assignment == gene_assignment:\n",
    "            return flair_id, flair_assignment, flair_biotype, flair_txn_id, 'match'\n",
    "        elif gene_assignment and not flair_assignment:\n",
    "            return gene_id, gene_assignment, gene_biotype, None, 'read_flair-failed'\n",
    "        elif flair_assignment and not gene_assignment:  # Issue here b/c flair assignment is a Nan float... not a Nonetype\n",
    "            if flair_chr == gene_chr:\n",
    "                return flair_id, flair_assignment, flair_biotype, flair_txn_id, 'flair_read-failed'\n",
    "            else:\n",
    "                return None, None, None, None, 'failed_read-failed_flair-vs-read-chr-mismatch'\n",
    "        elif flair_assignment and gene_assignment:\n",
    "            return gene_id, gene_assignment, gene_biotype, None, 'read_flair-vs-read-mismatch'\n",
    "        else:\n",
    "            return None, None, None, None, 'failed_no-assignment'\n",
    "    gtf_df = pd.read_parquet(\"/data16/marcus/genomes/elegansRelease100/Caenorhabditis_elegans.WBcel235.100.gtf.parquet\")\n",
    "    transcript_gtf_df = gtf_df.query(\"feature == 'transcript'\")[['chr', 'transcript_id', 'gene_id', 'gene_name', 'gene_biotype', 'transcript_biotype']]\n",
    "    transcript_gtf_df.rename(columns={'chr': 'chr_id'}, inplace=True)\n",
    "    gene_gtf_df = gtf_df.query(\"feature == 'gene'\")[['gene_id', 'gene_name', 'gene_biotype']]\n",
    "    \n",
    "    reads_df = pd.read_parquet(npCommon.pick_lib_return_path(lib_key, file_midfix='_mergedOnReads', file_suffix='.parquet'))\n",
    "    reads_df = reads_df.merge(gene_gtf_df, how='left', on=['gene_id', 'gene_name']).set_index('read_id')\n",
    "    \n",
    "    \n",
    "    flair_wide_df = pd.read_table(npCommon.pick_lib_return_path(lib_key, output_dir_folder=\"flair\", file_midfix='isoform.read.map', file_suffix='.txt'), sep='\\t', names=['transcript_id', 'read_ids'])\n",
    "    flair_wide_df['read_id'] = flair_wide_df.read_ids.str.split(',')\n",
    "    flair_df = flair_wide_df.explode('read_id').reset_index(drop=True)[['read_id', 'transcript_id']]\n",
    "    flair_df = flair_df.merge(transcript_gtf_df, how='left', on='transcript_id').set_index('read_id')\n",
    "    \n",
    "    reads_df['in_reads_df'] = True\n",
    "    flair_df['in_flair_df'] = True\n",
    "    \n",
    "    l_merge_df = pd.merge(reads_df, flair_df, how='left',\n",
    "                          on='read_id',\n",
    "                          suffixes=('_fromReads', '_fromFlair'))\n",
    "    l_merge_df.in_flair_df.fillna(False, inplace=True)\n",
    "    l_merge_df.in_reads_df.fillna(False, inplace=True)\n",
    "    \n",
    "    o_merge_df = pd.merge(reads_df, flair_df, how='outer',\n",
    "                          on='read_id',\n",
    "                          suffixes=('_fromReads', '_fromFlair'))\n",
    "    if print_stats:\n",
    "        print(f\"\\n\"\n",
    "              f\"Total FLAIR assigned reads:       {flair_df.shape[0]:>20,}\\n\"\n",
    "              f\"Total nonFLAIR assigned reads:    {reads_df.shape[0]:>20,}\\n\"\n",
    "              f\"Total reads after merge:          {l_merge_df.shape[0]:>20,}\\n\"\n",
    "              f\"Reads from FLAIR that didnt make it:{o_merge_df.shape[0] - l_merge_df.shape[0]:>18,}\\n\"\n",
    "              f\"Reads not assigned by FLAIR:      {l_merge_df.in_flair_df.value_counts()[False]:>20,}\"\n",
    "              f\" <-- These are the ambiguous reads(?)\\n\",\n",
    "              )\n",
    "    \n",
    "    l_merge_df.rename(columns={'chr_id_fromReads': 'chr_id'}, inplace=True)\n",
    "    l_merge_df['lib'] = CONVERSION_DICT[lib_key]\n",
    "    \n",
    "    if isinstance(path_to_dir_for_assignment_plot, str):\n",
    "        new_df = pd.DataFrame()\n",
    "        new_df['matched_assignment'] = l_merge_df.gene_name_fromFlair == l_merge_df.gene_name_fromReads\n",
    "        new_df['assigned_by_FLAIR'] = ~l_merge_df.gene_name_fromFlair.isna()\n",
    "        new_df['assigned_by_READS'] = ~l_merge_df.gene_name_fromReads.isna()\n",
    "        \n",
    "        new_df['matched_chrs'] = l_merge_df.chr_id == l_merge_df.chr_id_fromFlair\n",
    "        \n",
    "        npCommon.boolDF_to_upsetPlot(new_df,\n",
    "                                     show_percentages=False,\n",
    "                                     file_name=f\"{path_to_dir_for_assignment_plot}/{npCommon.get_dt()}_assignmentsUpsetPlots_{CONVERSION_DICT[lib_key]}.png\",\n",
    "                                     )\n",
    "    \n",
    "    cols_to_drop = ('gene_name_fromFlair',\n",
    "                    'gene_biotype_fromFlair',\n",
    "                    'gene_id_fromFlair',\n",
    "                    'chr_id_fromFlair',\n",
    "                    'transcript_id',\n",
    "                    'gene_name_fromReads',\n",
    "                    'gene_biotype_fromReads',\n",
    "                    'gene_id_fromReads',\n",
    "                    'transcript_biotype',\n",
    "                    'in_reads_df',\n",
    "                    'in_flair_df',\n",
    "                    'chr',\n",
    "                    )\n",
    "    \n",
    "    l_merge_final_columns = [col for col in l_merge_df.columns.tolist() if col not in cols_to_drop]\n",
    "    new_assignment_columns = ['gene_id', 'gene_name', 'gene_biotype', 'transcript_id', 'assignment_tag']\n",
    "    l_merge_final_columns += new_assignment_columns\n",
    "    \n",
    "    l_merge_df = l_merge_df.where(pd.notnull(l_merge_df), None)\n",
    "    \n",
    "    if print_stats:\n",
    "        tqdm.pandas(desc='Correcting gene/transcript assignments')\n",
    "        l_merge_df[new_assignment_columns] = l_merge_df.progress_apply(_pick_correct_gene_assignment, axis=1, result_type='expand')\n",
    "    else:\n",
    "        l_merge_df[new_assignment_columns] = l_merge_df.apply(_pick_correct_gene_assignment, axis=1, result_type='expand')\n",
    "    \n",
    "    \n",
    "    return l_merge_df[l_merge_final_columns]\n",
    "\n",
    "def long_to_wide(input_df, wide_target_cols=['gene_rpm'], expand_col='lib', fillna=True) -> pd.DataFrame:\n",
    "    w = input_df[wide_target_cols].unstack(level=expand_col)\n",
    "    w.columns = w.columns.map('{0[0]}_{0[1]}'.format)\n",
    "    if fillna:\n",
    "        return w.reset_index().fillna(0)\n",
    "    else:\n",
    "        return w.reset_index()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "regenerate = False\n",
    "print_per_lib_loading_stats = True\n",
    "save_read_assignments_upset_dir = \"./output_files/assignment_plots\"  # Set to none if you don't want to make these plots\n",
    "\n",
    "libs_to_load = sorted({\n",
    "    \"oldN2\",\n",
    "    \"oldS6\",\n",
    "    # \"newN2\",\n",
    "    \"newerN2\",\n",
    "    \"newerS5\",\n",
    "    \"newerS6\",\n",
    "    # \"newS5\",\n",
    "    # \"newS6\",\n",
    "    # \"newS7\",\n",
    "    # \"sPM57\",\n",
    "    # \"sPM58\",\n",
    "    })\n",
    "try:\n",
    "    if regenerate:\n",
    "        raise ValueError\n",
    "    reads_df_raw_path = npCommon.find_newest_matching_file(f\"./output_files/mega_merge_parquets/*_{'-'.join(libs_to_load)}_5TERA.reads_df.transcriptsAndGenes.parquet\")\n",
    "    print(f\"Found preprocessed file at:\\n\\t{reads_df_raw_path}\")\n",
    "    reads_df_raw = pd.read_parquet(reads_df_raw_path)\n",
    "except ValueError:\n",
    "    print(f\"Could not find preprocessed files matching these libs: {'/'.join(libs_to_load)}\\n\"\n",
    "          f\"Going to create new ones from scratch! This will take longer.\")\n",
    "    lib_dict = {}\n",
    "    for library in libs_to_load:\n",
    "        lib_dict[library] = load_flair_and_reads(\n",
    "            REV_CONVERSION_DICT[library],\n",
    "            path_to_dir_for_assignment_plot=save_read_assignments_upset_dir,\n",
    "            print_stats=print_per_lib_loading_stats,\n",
    "        )\n",
    "    if len(libs_to_load) == 1:\n",
    "        reads_df_raw = lib_dict[library]\n",
    "    else:\n",
    "        reads_df_raw = pd.concat(list(lib_dict.values()))\n",
    "    \n",
    "    print(f\"Saving new parquets to speed up future runs.\")\n",
    "    reads_df_raw.to_parquet(f\"./output_files/mega_merge_parquets/{npCommon.get_dt()}_{'-'.join(libs_to_load)}_5TERA.reads_df.transcriptsAndGenes.parquet\")\n",
    "\n",
    "print(f\"Lib load done @ {npCommon.get_dt(for_print=True)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Now lets plot this thing!!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plots_tails_ecdf(library_df, targeted_gene,\n",
    "                     lib_target,\n",
    "                     save_dir=f\"./output_files/isoform_plots/NMD_and_Adapted_tailPlots\",\n",
    "                     given_ax=None,\n",
    "                     log_xaxis=True,\n",
    "                     ):\n",
    "    palette = {\"NMD'ed: +  t5: -\": \"darkred\",\n",
    "               \"NMD'ed: +  t5: +\": \"red\", \n",
    "               \"NMD'ed: -  t5: -\": \"darkblue\",\n",
    "               \"NMD'ed: -  t5: +\": \"blue\",\n",
    "               \"NMD'ed: ~  t5: -\": \"darkgray\",\n",
    "               \"NMD'ed: ~  t5: +\": \"gray\"}\n",
    "    \n",
    "    if given_ax:\n",
    "        ax = given_ax\n",
    "    else:\n",
    "        _, ax = plt.subplots(figsize=(8, 6))\n",
    "    g = sea.ecdfplot(library_df.sort_values('NMD_and_t5'),\n",
    "                     ax=ax,\n",
    "                     x='polya_length',\n",
    "                     hue='NMD_and_t5',\n",
    "                     palette=palette,\n",
    "                     log_scale=log_xaxis,\n",
    "                     )\n",
    "    # Change the line styles:\n",
    "    for i, line in enumerate(g.lines):\n",
    "        if line.get_color().startswith(\"dark\"):\n",
    "            line.set_linestyle(\"-\")\n",
    "        else:\n",
    "            line.set_linestyle(\"--\")\n",
    "    if not given_ax:\n",
    "        plt.title(f\"Tail lengths from {lib_target} for {targeted_gene}\")\n",
    "    if log_xaxis:\n",
    "        ax.set_xbound(10, 200)\n",
    "        ax.set_xticks([10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200])\n",
    "        ax.set_xticklabels([10, 20, 30, 40, 50, None, 70, None, None, 100, 200])\n",
    "    else:\n",
    "        ax.set_xbound(-1, 200)\n",
    "    # sea.move_legend(g, \"lower right\")\n",
    "    ax.get_legend().remove()\n",
    "    if not given_ax:\n",
    "        plt.tight_layout()\n",
    "    if isinstance(save_dir, str):\n",
    "        save_dir = Path(save_dir)\n",
    "        if not save_dir.exists():\n",
    "            print(f\"Making new directory at: {save_dir}\")\n",
    "            save_dir.mkdir()\n",
    "        \n",
    "        save_path = str(save_dir) + f\"/{npCommon.get_dt()}_{targeted_gene}_{lib_target}_NMD-and-t5_tailLength.ecdf\"\n",
    "        if log_xaxis:\n",
    "            save_path += \".logAxis\"\n",
    "        for file_type in ['.svg', '.png']:\n",
    "            plt.savefig(save_path + file_type, dpi=300)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plots_tails_violin(library_df, targeted_gene,\n",
    "                     lib_target,\n",
    "                     save_dir=f\"./output_files/isoform_plots/NMD_and_Adapted_tailPlots\",\n",
    "                     given_ax=None,\n",
    "                     log_yaxis=True,\n",
    "                     ):\n",
    "    palette = {\"NMD'ed: +  t5: -\":\"darkred\",\n",
    "               \"NMD'ed: +  t5: +\":\"red\", \n",
    "               \"NMD'ed: -  t5: -\":\"darkblue\",\n",
    "               \"NMD'ed: -  t5: +\":\"blue\",\n",
    "               \"NMD'ed: ~  t5: -\":\"darkgray\",\n",
    "               \"NMD'ed: ~  t5: +\":\"gray\"}\n",
    "    \n",
    "    if given_ax:\n",
    "        ax = given_ax\n",
    "    else:\n",
    "        _, ax = plt.subplots(figsize=(8, 6))\n",
    "    g = sea.violinplot(library_df.sort_values('NMD_and_t5'),\n",
    "                       ax=ax,\n",
    "                       y='polya_length',\n",
    "                       x='NMD_Sensitive_Isoform',\n",
    "                       hue='t5',\n",
    "                       # palette=palette,\n",
    "                       cut=0,\n",
    "                       split=True,\n",
    "                       inner='stick',\n",
    "                       )\n",
    "    if not given_ax:\n",
    "        plt.title(f\"Tail lengths from {lib_target} for {targeted_gene}\")\n",
    "    if log_yaxis:\n",
    "        ax.set_ybound(10, 200)\n",
    "        ax.set_yticks([10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200])\n",
    "        ax.set_yticklabels([10, 20, 30, 40, 50, None, 70, None, None, 100, 200])\n",
    "    else:\n",
    "        ax.set_ybound(-1, 200)\n",
    "    # sea.move_legend(g, \"lower right\")\n",
    "    # ax.get_legend().remove()\n",
    "    if not given_ax:\n",
    "        plt.tight_layout()\n",
    "    if isinstance(save_dir, str):\n",
    "        save_dir = Path(save_dir)\n",
    "        if not save_dir.exists():\n",
    "            print(f\"Making new directory at: {save_dir}\")\n",
    "            save_dir.mkdir()\n",
    "        \n",
    "        save_path = str(save_dir) + f\"/{npCommon.get_dt()}_{targeted_gene}_{lib_target}_NMD-and-t5_tailLength.violin\"\n",
    "        if log_yaxis:\n",
    "            save_path += \".logAxis\"\n",
    "        for file_type in ['.svg', '.png']:\n",
    "            plt.savefig(save_path + file_type, dpi=300)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_tails_and_coverage(df, target_gene, lib,\n",
    "                            quiet=False, save_dir=None,\n",
    "                            seaborn_context='talk',\n",
    "                            log_tails=True,\n",
    "                            ecdf_tails=True):\n",
    "    sea.set_style(\"whitegrid\")\n",
    "    sea.set_context(seaborn_context)\n",
    "    \n",
    "    \n",
    "    ### Process dataframe >>>\n",
    "    df = df.query(f\"lib == '{lib}'\")\n",
    "    \n",
    "    try:\n",
    "        iso_edge, left_or_right, NMD_sensitive_txns = TARGETS_AND_ISOEDGE_DICT[target_gene]\n",
    "    except KeyError:\n",
    "        raise KeyError(f\"Currently only these genes have the necessary information for this full analysis:\\n{list(TARGETS_AND_ISOEDGE_DICT.keys())}\")\n",
    "    \n",
    "    if left_or_right == 'left':\n",
    "        comparator = \"<=\"\n",
    "        anti_comparator = \">=\"\n",
    "    elif left_or_right == 'right':\n",
    "        comparator = \">=\"\n",
    "        anti_comparator = \"<=\"\n",
    "    else:  # This is just to shut pycharm up\n",
    "        comparator = None\n",
    "        anti_comparator = None\n",
    "    \n",
    "    nmd_sensitive_genes_and_txns_dict = {potential_target_gene: NMD_sensitive_txns for potential_target_gene, (_, _, NMD_sensitive_txns) in TARGETS_AND_ISOEDGE_DICT.items()}\n",
    "    print(nmd_sensitive_genes_and_txns_dict[target_gene])\n",
    "    df['NMD_Sensitive_Isoform'] = df['transcript_id'].isin(nmd_sensitive_genes_and_txns_dict[target_gene]).replace({True: '+', False: '-'})\n",
    "    df.NMD_Sensitive_Isoform.mask(((df.t5 == '+') & (df.eval(f\"chr_pos {anti_comparator} {iso_edge}\"))), '~', inplace=True)\n",
    "    df.NMD_Sensitive_Isoform.mask(df.transcript_id.isna(), '~', inplace=True)\n",
    "    df['NMD_and_t5'] = df.apply(lambda row: f\"NMD'ed: {str(row['NMD_Sensitive_Isoform'])}  t5: {row['t5']}\", axis=1)\n",
    "    ### <<< Process dataframe\n",
    "    \n",
    "    \n",
    "    ### Build plot >>>\n",
    "    single_nest = [\n",
    "        ['target_adapted', 'tails'],\n",
    "        ['target_unadapted', 'tails'],\n",
    "        ['non_target_adapted', 'tails'],\n",
    "        ['non_target_unadapted', 'tails'],\n",
    "        ['ambiguous_adapted', 'tails'],\n",
    "        ['ambiguous_unadapted', 'tails'],\n",
    "        ['space_for_annotations', 'tails']\n",
    "    ]\n",
    "    fig, axd = plt.subplot_mosaic(single_nest,\n",
    "                                  # layout=\"constrained\",\n",
    "                                  figsize=(15,7),\n",
    "                                  height_ratios=(1,2,1,2,1,2,1), \n",
    "                                  width_ratios=(2,4))\n",
    "    \n",
    "    adapted_axes = [ax for name, ax in axd.items() if name.endswith('_adapted')]\n",
    "    unadapted_axes = [ax for name, ax in axd.items() if name.endswith('_unadapted')]\n",
    "    ### <<< Build plot\n",
    "    \n",
    "    \n",
    "    ### Plot coverage >>>\n",
    "    assignment_types_axes = []\n",
    "    for assignment_type in ['target', 'non_target', 'ambiguous']:\n",
    "        assignment_types_axes.append([ax for name, ax in axd.items() if name.startswith(assignment_type)])\n",
    "    \n",
    "    plot_colors = ('red', 'blue', 'gray')\n",
    "    \n",
    "    axes_iterator = zip(['+', '-', '~'], assignment_types_axes, plot_colors)\n",
    "    for assignment, assignment_axes, plot_color in axes_iterator:  # Either two steps here or three (if ambiguous reads getting plotted!)\n",
    "        print(f\"Calculating coverage for NMD-({assignment}) isoform in {lib} library:\")\n",
    "        # print(lib_df.query(f\"NMD_Sensitive_Isoform == '{target}'\"))\n",
    "        print(assignment, assignment_axes)\n",
    "        coverage_plotting_5tera(df,\n",
    "                                gene_name=target_gene,\n",
    "                                provide_axes=assignment_axes,\n",
    "                                rpm_normalize=True,\n",
    "                                additional_plot_df_query=f\"NMD_Sensitive_Isoform == '{assignment}'\",\n",
    "                                quiet=quiet,\n",
    "                                adapted_color=plot_color,\n",
    "                                unadapted_color='dark' + plot_color,\n",
    "                                )\n",
    "    \n",
    "    adapted_axes[0].get_shared_y_axes().join(*adapted_axes)\n",
    "    unadapted_axes[0].get_shared_y_axes().join(*unadapted_axes)\n",
    "    \n",
    "    for ax in adapted_axes + unadapted_axes:\n",
    "        ax.yaxis.get_major_ticks()[1].label1.set_visible(False)\n",
    "    \n",
    "    ### <<< Plot coverage\n",
    "    \n",
    "    ### Plot tails >>>\n",
    "    gene_df = df.query(f\"gene_name == '{target_gene}'\")\n",
    "    if ecdf_tails:\n",
    "        plots_tails_ecdf(gene_df, target_gene, lib,\n",
    "                         given_ax=axd['tails'],\n",
    "                         save_dir=None,\n",
    "                         log_xaxis=log_tails,\n",
    "                         )\n",
    "    else:\n",
    "        plots_tails_violin(gene_df, target_gene, lib,\n",
    "                           given_ax=axd['tails'],\n",
    "                           save_dir=None,\n",
    "                           log_yaxis=log_tails)\n",
    "    ### <<< Plot tails\n",
    "    \n",
    "    ### Final cleanup >>>\n",
    "    annotation_ax = axd['space_for_annotations']\n",
    "    annotation_ax.grid(False)\n",
    "    annotation_ax.axis('off')\n",
    "    annotation_ax.set_xticklabels([])\n",
    "    annotation_ax.set_yticklabels([])\n",
    "    plt.subplots_adjust(wspace=0.25, hspace=0.30)\n",
    "    plt.suptitle(f'{target_gene} in {lib}')\n",
    "    ### <<< Final cleanup\n",
    "    \n",
    "    ### Save plot >>>\n",
    "    if isinstance(save_dir, str):\n",
    "        save_dir = Path(save_dir)\n",
    "        if not save_dir.exists():\n",
    "            save_dir.mkdir()\n",
    "        plot_file_name = f\"{npCommon.get_dt()}_{target_gene}_{lib}_coverageAndTailsPlots\"\n",
    "        for file_type in ('.svg', '.png'):\n",
    "            save_path = str(save_dir) + '/' + plot_file_name + file_type\n",
    "            plt.savefig(save_path)\n",
    "    else:\n",
    "        plt.show()\n",
    "    ### <<< Save plot\n",
    "    return fig, axd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "libraries = (\n",
    "    # 'oldN2',\n",
    "    # 'oldS6',\n",
    "    # 'newN2',\n",
    "    # 'newS6',\n",
    "    # 'newS5',\n",
    "    'newerN2',\n",
    "    'newerS5',\n",
    "    'newerS6',\n",
    ")\n",
    "\n",
    "target_genes = (\n",
    "    # 'ubl-1',\n",
    "    # 'rpl-30',\n",
    "    # 'rps-22',\n",
    "    'rpl-3',\n",
    "    # 'xbp-1',\n",
    "    # 'zip-1',\n",
    "    # 'ets-4',\n",
    ")\n",
    "\n",
    "\n",
    "for library in libraries:\n",
    "    for gene_to_plot in target_genes:\n",
    "        lib_df = reads_df_raw.copy(deep=True).query(f\"lib == '{library}'\")  #.sample(10000)\n",
    "        plot_tails_and_coverage(lib_df,\n",
    "                                gene_to_plot,\n",
    "                                library,\n",
    "                                save_dir=f\"/home/marcus/Insync/marcus.viscardi@gmail.com/Google Drive/insync_folder/5TERA_ReadsAndTails_Plots/raw_figures_from_python/{npCommon.get_dt()}_coverageAndTails_{'-'.join(libraries)}_{'-'.join(target_genes)}\",\n",
    "                                quiet=True,\n",
    "                                log_tails=True,\n",
    "                                ecdf_tails=True,\n",
    "                                )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Assessing the results:\n",
    "\n",
    "Generally, I think this worked really well. There are some details holding it back from being perfect:\n",
    "1. I think the tail plot section needs to be a bit wider to emphasize the difference between all of these different statuses.\n",
    "2. For genes like rps-22 that have a lot of very similar isoforms, there are a bunch of reads dropping into the \"ambiguous\" category. This is not because they are not obviously the NMD isoform or not, but rather they are multiply mapping to the OTHER isoforms and failing to get a singular \"best\" map.\n",
    "3. Still need to be able to plot the isoforms!! but inkscape will continue to work for this... I guess... lol"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "# Tail Scatter plots\n",
    "\n",
    "The goal for this is to produce two scatter plots for each *smg-5* and *smg-6*. These plots will be:\n",
    "1. WT full length NMD isoform polyA tails vs. WT deg. Intermediate NMD isoform polyA tails\n",
    "2. WT full length NMD isoform polyA tails vs. *smg-6*/*smg-5* full length NMD isoform polyA tails\n",
    "\n",
    "***\n",
    "\n",
    "I think I can produce a version of \"plot 2\" with the curated list from above fairly quickly. If I decide to use a less stringent list in the future I can just add that to this code!\n",
    "\n",
    "The main problem with \"plot 1\" is that I'll need to decide what degradation intermediates to call NMD derived when the necessary isoform information is gone! Some options:\n",
    "\n",
    "1. Just call all degradation intermediates NMD derived (very content, but could mask signal?)\n",
    "2. Call all ambiguous deg. intermediates NMD derived (less consistent but ensures that I am not adding decapped reads)\n",
    "\n",
    "***\n",
    "\n",
    "For now, I'll get \"plot 2\" working, then circle back to figure this all out."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "target_lib_sets = (# ('oldN2', 'oldS6'),\n",
    "                   # ('newN2', 'newS5'),\n",
    "                   # ('newN2', 'newS6'),\n",
    "                   # ('newS5', 'newS6'),\n",
    "                   # ('oldS6', 'newS6'),\n",
    "                   # ('oldN2', 'newerN2'),\n",
    "                   # ('oldN2', 'oldS6'),\n",
    "                   # ('oldN2', 'newerS6'),\n",
    "                   # ('oldN2', 'newerS5'),\n",
    "                   ('newerS6', 'newerS5'),\n",
    "                   # ('newerN2', 'newerS5'),\n",
    "                   # ('newerN2', 'newerS6')\n",
    "                   )\n",
    "\n",
    "save_dir = f\"/home/marcus/Insync/mviscard@ucsc.edu/Google Drive/insync_folder/NMD_cleavage_and_deadenylation_paper/raw_figures_from_python/{npCommon.get_dt()}_tailScatters\"\n",
    "if not Path(save_dir).exists():\n",
    "    Path(save_dir).mkdir()\n",
    "\n",
    "targets_and_iso_edge_dictionary = TARGETS_AND_ISOEDGE_DICT\n",
    "direction_to_comparator = {'left': (\"<=\", \">=\"),\n",
    "                           'right': (\">=\", \"<=\")}\n",
    "\n",
    "def _apply_per_gene_adjustments(gene_name=None, transcript_id=None,\n",
    "                                t5=None, chr_pos=None, call_adapted_species_NMD_derived=False,\n",
    "                                **other_kwargs):\n",
    "        try:\n",
    "            iso_edge, left_or_right, NMD_sensitive_txns = targets_and_iso_edge_dictionary[gene_name]\n",
    "            comparator, anti_comparator = direction_to_comparator[left_or_right]\n",
    "        except KeyError:\n",
    "            print(f\"Currently only these genes have the necessary information for this full analysis:\\n {list(targets_and_iso_edge_dictionary.keys())}\\n You should try to filter your dataframe before running this function\")\n",
    "            from pprint import pprint\n",
    "            print(gene_name)\n",
    "            dir_values = {key: eval(key) for key in dir()}\n",
    "            pprint(dir_values)\n",
    "            raise KeyError\n",
    "        \n",
    "        if transcript_id in NMD_sensitive_txns:\n",
    "            NMD_sensitive_isoform = '+'\n",
    "        else:\n",
    "            NMD_sensitive_isoform = '-'\n",
    "        \n",
    "        chr_position = chr_pos  # This is used in the below evaluate function\n",
    "        if t5 == '+' and eval(f\"chr_position {anti_comparator} {iso_edge}\"):\n",
    "            NMD_sensitive_isoform = '~'\n",
    "        if not transcript_id:\n",
    "            NMD_sensitive_isoform = '~'\n",
    "        \n",
    "        if call_adapted_species_NMD_derived and t5 == '+':\n",
    "            NMD_sensitive_isoform = '+'\n",
    "        \n",
    "        NMD_and_t5 = f\"NMD'ed: {NMD_sensitive_isoform}  t5: {t5}\"\n",
    "        \n",
    "        return NMD_sensitive_isoform, NMD_and_t5\n",
    "\n",
    "\n",
    "def plot_tails_scatter(input_df, save_directory=None, split_column='lib',\n",
    "                       flip_split_col_order=True, fill_na=False,\n",
    "                       plot_limits=(0, 150), plot_line_step=25) -> pd.DataFrame:\n",
    "    \n",
    "    split_col_values = input_df[split_column].unique().tolist()\n",
    "    num_split_col_values = len(split_col_values)\n",
    "    \n",
    "    if num_split_col_values != 2:\n",
    "        raise NotImplementedError(f\"You provided a dataframe with {num_split_col_values} unique values in the split column ({', '.join(split_col_values)}), please only provide two. This will allow the values to be plotted!\")\n",
    "    if flip_split_col_order:\n",
    "        y_val, x_val = split_col_values\n",
    "    else:\n",
    "        x_val, y_val = split_col_values\n",
    "    \n",
    "    groupby = input_df.groupby([split_column, \"gene_name\"])\n",
    "    new_df = pd.DataFrame()\n",
    "    new_df['mean_tail'] = groupby['polya_length'].mean()\n",
    "    new_df['error'] = groupby['polya_length'].sem()  # standard error of the mean\n",
    "    new_df['counts'] = groupby['polya_length'].count()\n",
    "    new_df = long_to_wide(new_df,\n",
    "                          wide_target_cols=['mean_tail', 'error', 'counts'],\n",
    "                          expand_col=split_column,\n",
    "                          fillna=fill_na)\n",
    "    sea.set_style(\"whitegrid\")\n",
    "    sea.set_context('poster')\n",
    "    plt.figure(figsize=(10, 7.4))\n",
    "    \n",
    "    # ###\n",
    "    # print(new_df)\n",
    "    # \n",
    "    # import matplotlib.patches\n",
    "    # \n",
    "    # levels, categories = pd.factorize(new_df['gene_name'])\n",
    "    # print(levels, categories)\n",
    "    # colors = {gene_name: plt.cm.tab10(i) for i, gene_name in enumerate(categories)} # using the \"tab10\" colormap\n",
    "    # handles = [matplotlib.patches.Patch(color=plt.cm.tab10(i), label=c) for i, c in enumerate(categories)]\n",
    "    # ###\n",
    "    marker_style_dict = {'ubl-1': '^',\n",
    "                         'aly-3': 'o',\n",
    "                         'hel-1': 'h',\n",
    "                         'K08D12.3': 'P',\n",
    "                         'odc-1': '8',\n",
    "                         'rpl-1': 'v',\n",
    "                         'rpl-12': 's',\n",
    "                         'rpl-26': 'H',\n",
    "                         'rpl-3': 'p',\n",
    "                         'rpl-30': 'D',\n",
    "                         'rps-22': '>',\n",
    "                         }\n",
    "    # marker_style_dict = {gene_name: f\"${gene_name}$\" for gene_name in new_df['gene_name'].unique()}\n",
    "    simple_marker_dict = {}\n",
    "    simple_color_dict = {}\n",
    "    for gene_name in marker_style_dict.keys():\n",
    "        if gene_name in ['ubl-1', 'rps-22', 'rpl-30']:\n",
    "            simple_marker_dict[gene_name] = 'P'\n",
    "            simple_color_dict[gene_name] = 'r'\n",
    "        else:\n",
    "            simple_marker_dict[gene_name] = 'o'\n",
    "            simple_color_dict[gene_name] = 'k'\n",
    "    sea.scatterplot(new_df,\n",
    "                    x=f'mean_tail_{x_val}',\n",
    "                    y=f'mean_tail_{y_val}',\n",
    "                    hue='gene_name',\n",
    "                    palette=simple_color_dict,\n",
    "                    style='gene_name',\n",
    "                    markers=simple_marker_dict,\n",
    "                    linewidth=0,\n",
    "                    zorder=2,\n",
    "                    # s=2500,\n",
    "                    )\n",
    "    plt.errorbar(x=new_df[f'mean_tail_{x_val}'],\n",
    "                 xerr=new_df[f'error_{x_val}'],\n",
    "                 y=new_df[f'mean_tail_{y_val}'],\n",
    "                 yerr=new_df[f'error_{y_val}'],\n",
    "                 fmt=' ',\n",
    "                 c='0.2',\n",
    "                 zorder=1,\n",
    "                 )\n",
    "    \n",
    "    min_plot, max_plot = plot_limits\n",
    "    plt.plot([min_plot-1, max_plot],\n",
    "             [min_plot-1, max_plot],\n",
    "             c='0.5',\n",
    "             linestyle='dashed',\n",
    "             zorder=0)\n",
    "    plt.xlim(min_plot-1, max_plot)\n",
    "    plt.ylim(min_plot-1, max_plot)\n",
    "    plt.xticks(range(min_plot, max_plot, plot_line_step))\n",
    "    plt.yticks(range(min_plot, max_plot, plot_line_step))\n",
    "    \n",
    "    if x_val.endswith(\"N2\") or y_val.endswith(\"N2\") or x_val[-2:] == y_val[-2:]:\n",
    "        print(x_val[-2:])\n",
    "        plt.xlabel(f'Tail Length ({x_val})\\n[Unadapted NMD Targets]')\n",
    "        plt.ylabel(f'Tail Length ({y_val})\\n[Unadapted NMD Targets]')\n",
    "        additional_save_file_tag = \"\"\n",
    "    else:\n",
    "        plt.xlabel(f'Tail Length ({x_val})')\n",
    "        plt.ylabel(f'Tail Length ({y_val})')\n",
    "        passed_libraries = input_df.lib.unique().tolist()\n",
    "        if len(passed_libraries) == 1:\n",
    "            additional_save_file_tag = f\"{passed_libraries[0]}_\"\n",
    "        else:\n",
    "            additional_save_file_tag = f\"{'-'.join(passed_libraries)}_\"\n",
    "    \n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_directory:\n",
    "        save_dir_path = Path(save_directory)\n",
    "        if not save_dir_path.exists():\n",
    "            save_dir_path.mkdir()\n",
    "        gene_list_path = save_dir_path / 'plotted_gene_list.txt'\n",
    "        if not gene_list_path.exists():\n",
    "            with open(gene_list_path, 'w') as f:\n",
    "                f.write('\\n'.join(TARGETS_AND_ISOEDGE_DICT.keys()))\n",
    "        for file_type in ('.svg', '.png'):\n",
    "            save_path = save_directory + f\"/{y_val}-{x_val}_{additional_save_file_tag}tailScatter_wSEM\" + file_type\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "            print(f\"Saving figure to {save_path}\")\n",
    "    else:\n",
    "        print(f\"Not saving figure to file...\")\n",
    "    plt.show()\n",
    "    return new_df\n",
    "\n",
    "\n",
    "def plot_tails_scatter_plotly(input_df, save_directory=None, split_column='lib',\n",
    "                              flip_split_col_order=False, fill_na=False,\n",
    "                              filter_w_counts_below=0, comment_to_pass=None,\n",
    "                              plot_limits=(0, 150), plot_line_step=25) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    I want to produce basically the same plot as plot_tails_scatter but with ploty,\n",
    "    specifically so that we can hover over the points and see the gene names, read counts, etc.\n",
    "    \n",
    "    This will help with deciding if we should be using some kind of cutoff for the weirder genes!\n",
    "    \"\"\"\n",
    "    # going to take the dataframe processing straight from plot_tails_scatter!\n",
    "    NMD_and_t5s = input_df['NMD_and_t5'].unique().tolist()\n",
    "    if len(NMD_and_t5s) == 1:\n",
    "        NMD_and_t5_inPlot = NMD_and_t5s[0]\n",
    "        print(f\"The plot dataframe contains only {NMD_and_t5_inPlot} targets!\")\n",
    "        single_NMD_and_t5 = True\n",
    "    else:\n",
    "        print(f\"The plot dataframe contains {len(NMD_and_t5s)} different NMD_and_t5 targets!\")\n",
    "        print(f\"These targets are: {', '.join(NMD_and_t5s)}\")\n",
    "        single_NMD_and_t5 = False\n",
    "    \n",
    "    \n",
    "    split_col_values = input_df[split_column].unique().tolist()\n",
    "    num_split_col_values = len(split_col_values)\n",
    "    \n",
    "    if num_split_col_values != 2:\n",
    "        raise NotImplementedError(f\"You provided a dataframe with {num_split_col_values} unique values in the split column ({', '.join(split_col_values)}), please only provide two. This will allow the values to be plotted!\")\n",
    "    if flip_split_col_order:\n",
    "        y_val, x_val = split_col_values\n",
    "    else:\n",
    "        x_val, y_val = split_col_values\n",
    "    \n",
    "    groupby = input_df.groupby([split_column, \"gene_name\"])\n",
    "    new_df = pd.DataFrame()\n",
    "    new_df['mean_tail'] = groupby['polya_length'].mean()\n",
    "    new_df['error'] = groupby['polya_length'].sem()  # standard error of the mean\n",
    "    new_df['counts'] = groupby['polya_length'].count()\n",
    "    new_df = long_to_wide(new_df,\n",
    "                          wide_target_cols=['mean_tail', 'error', 'counts'],\n",
    "                          expand_col=split_column,\n",
    "                          fillna=fill_na)\n",
    "    \n",
    "    if filter_w_counts_below > 0:\n",
    "        print(f\"Dropping genes with less than {filter_w_counts_below} poly(A) tail called reads in either {x_val} or {y_val}...\")\n",
    "        failed_df = new_df[(new_df[f'counts_{x_val}'] < filter_w_counts_below) | (new_df[f'counts_{y_val}'] < filter_w_counts_below)]\n",
    "        print(f\"Failed genes:\")\n",
    "        print(f\"{'gene_name':>15}{f'counts_{x_val}':>15}{f'counts_{y_val}':>15}\")\n",
    "        for index, row in failed_df.iterrows():\n",
    "            print(f\"{row['gene_name']:>15}{row[f'counts_{x_val}']:>15}{row[f'counts_{y_val}']:>15}\")\n",
    "        new_df = new_df[(new_df[f'counts_{x_val}'] >= filter_w_counts_below) & (new_df[f'counts_{y_val}'] >= filter_w_counts_below)]\n",
    "    \n",
    "    # Change plotly style to whitegrid\n",
    "    px.defaults.template = \"plotly_white\"\n",
    "    fig = px.scatter(new_df,\n",
    "                     x=f\"mean_tail_{x_val}\",\n",
    "                     y=f\"mean_tail_{y_val}\",\n",
    "                     error_x=f'error_{x_val}',\n",
    "                     error_y=f'error_{y_val}',\n",
    "                     text='gene_name',\n",
    "                     # textposition='top right',\n",
    "                     hover_name='gene_name',\n",
    "                     hover_data=[f'counts_{x_val}',\n",
    "                                 f'counts_{y_val}'],                     \n",
    "                     )\n",
    "    fig.update_traces(marker=dict(size=8,\n",
    "                                  line=dict(width=2,\n",
    "                                            color='black'),\n",
    "                                  color='black'),\n",
    "                      textposition='top right',\n",
    "                      )\n",
    "    # Make the axis limits the same\n",
    "    min_plot, max_plot = plot_limits\n",
    "    fig.add_shape(type='line',\n",
    "                  x0=min_plot-1, y0=min_plot-1,\n",
    "                  x1=max_plot, y1=max_plot,\n",
    "                  line=dict(color='DarkSlateGrey', width=2, dash='dash'),\n",
    "                  )\n",
    "    x_title = f'Tail Length ({x_val})'\n",
    "    y_title = f'Tail Length ({y_val})'\n",
    "    if comment_to_pass:\n",
    "        x_title += f\"<br>[{comment_to_pass}]\"\n",
    "        y_title += f\"<br>[{comment_to_pass}]\"\n",
    "    fig.update_layout(\n",
    "        xaxis_title=x_title,\n",
    "        yaxis_title=y_title,\n",
    "        xaxis=dict(range=[min_plot-1, max_plot], constrain='domain'),\n",
    "        yaxis=dict(range=[min_plot-1, max_plot], constrain='domain'),\n",
    "        )\n",
    "    # Make the overall plot square\n",
    "    fig.update_layout(\n",
    "        width=500,\n",
    "        height=500,\n",
    "        )\n",
    "    fig.show(renderer='firefox')\n",
    "    if Path(save_directory).exists():\n",
    "        save_path = save_directory + f\"/{npCommon.get_dt()}_tailScatter_{x_val}_vs_{y_val}\"\n",
    "        if single_NMD_and_t5:\n",
    "            save_path += f\".{NMD_and_t5_inPlot}\"\n",
    "        else:\n",
    "            save_path += f\".{'__'.join(NMD_and_t5s)}\"\n",
    "        print(f\"Saving figure to {save_path}\")\n",
    "        fig.write_html(save_path + \".html\")\n",
    "        fig.write_image(save_path + \".png\")\n",
    "        fig.write_image(save_path + \".svg\")\n",
    "    else:\n",
    "        print(f\"Not saving figure to file... Please provide a save_directory that exists!\")\n",
    "    \n",
    "\n",
    "nmd_sensitive_genes = list(targets_and_iso_edge_dictionary.keys())\n",
    "print(f\"Going to produce tail scatter plot with these {len(nmd_sensitive_genes)} genes:\\n    {', '.join(nmd_sensitive_genes)}\")\n",
    "\n",
    "for lib_set in target_lib_sets:\n",
    "    lib1, lib2 = lib_set\n",
    "    print(f\"Plotting tail scatter for libraries {lib_set[0]} & {lib_set[1]}:\")\n",
    "    lib_set_df = reads_df_raw[reads_df_raw.lib.isin(lib_set)].copy(deep=True)\n",
    "    lib_set_read_count = lib_set_df.shape[0]\n",
    "    \n",
    "    lib_set_df = lib_set_df[lib_set_df.gene_name.isin(nmd_sensitive_genes)]\n",
    "    curated_genes_read_count = lib_set_df.shape[0]\n",
    "    \n",
    "    print(f\"Only {curated_genes_read_count} of {lib_set_read_count} ({curated_genes_read_count/lib_set_read_count:2.2%}) reads are within the curated list of NMD genes.\")\n",
    "    \n",
    "    tqdm.pandas(desc=\"Identifying reads as NMD-target, non-target, or ambiguous\")\n",
    "    lib_set_df[['NMD_sensitive_isoform', 'NMD_and_t5']] = lib_set_df.progress_apply(lambda row: _apply_per_gene_adjustments(**row), axis=1, result_type='expand')\n",
    "    \n",
    "    lib_set_full_length_target_df = lib_set_df.query(\"\"\"NMD_and_t5 == \"NMD'ed: +  t5: -\" \"\"\")\n",
    "    # print(lib_set_full_length_target_df)\n",
    "    plot_tails_scatter_plotly(lib_set_full_length_target_df, save_directory=save_dir,\n",
    "                              plot_limits=(40, 140), plot_line_step=25,\n",
    "                              filter_w_counts_below=9,\n",
    "                              flip_split_col_order=True,\n",
    "                              comment_to_pass='Full-length NMD target Isoforms',\n",
    "                              )\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ***I NEED MORE EXAMPLE GENES!!***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Make the WT unadapted vs WT adapted scatter plot next:\n",
    "\n",
    "I'll scrape a bunch of the same processing code then just change what is plotted\n",
    "\n",
    "The code currently works, but the analysis is FLAWED. This is because of the high number of ambiguous reads not making it into this! (This is one of the main problems I noted up above)\n",
    "\n",
    "My current solution is going to be calling ALL adapted species NMD-targeted... This is mad hacky, but it will work for now."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "target_libraries = (# 'oldN2',\n",
    "                    'newerN2',\n",
    "                    # 'newerS6',\n",
    "                    # 'newerS5',\n",
    "                    )\n",
    "NMD_and_t5s_to_compare = ((\"NMD'ed: +  t5: -\", \"NMD'ed: +  t5: +\"),\n",
    "                          (\"NMD'ed: -  t5: -\", \"NMD'ed: +  t5: +\"),\n",
    "                          )\n",
    "for target_library in target_libraries:\n",
    "    temp_save_dir = save_dir + f\"/{target_library}\"\n",
    "    Path(temp_save_dir).mkdir(parents=True, exist_ok=True)\n",
    "    lib_df = reads_df_raw[reads_df_raw.lib == target_library].copy(deep=True)\n",
    "    lib_read_count = lib_df.shape[0]\n",
    "    lib_df = lib_df[lib_df.gene_name.isin(nmd_sensitive_genes)]\n",
    "    curated_genes_read_count = lib_df.shape[0]\n",
    "    \n",
    "    print(f\"Only {curated_genes_read_count} of {lib_read_count} ({curated_genes_read_count/lib_read_count:2.2%}) reads are within the curated list of NMD genes.\")\n",
    "    \n",
    "    tqdm.pandas(desc=\"Identifying reads as NMD-target, non-target, or ambiguous\")\n",
    "    lib_df[['NMD_sensitive_isoform', 'NMD_and_t5']] = lib_df.progress_apply(lambda row: _apply_per_gene_adjustments(call_adapted_species_NMD_derived=True, **row), axis=1, result_type='expand')\n",
    "    for i, NMD_and_t5_to_compare in enumerate(NMD_and_t5s_to_compare):\n",
    "        plot_df = lib_df[lib_df.NMD_and_t5.isin(NMD_and_t5_to_compare)]\n",
    "        if i == 0: flip = True\n",
    "        else: flip = False\n",
    "        output_df = plot_tails_scatter_plotly(plot_df, split_column=\"NMD_and_t5\", fill_na=True,\n",
    "                                  flip_split_col_order=flip, save_directory=temp_save_dir,\n",
    "                                  plot_limits=(30, 130), plot_line_step=25,\n",
    "                                  filter_w_counts_below=9,\n",
    "                                  )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "quicksave = f\"/tmp/{npCommon.get_dt()}_{target_library}.lib_df.parquet\"\n",
    "lib_df.to_parquet(quicksave)\n",
    "print(quicksave)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
